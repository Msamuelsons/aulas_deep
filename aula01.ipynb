{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lerning_rate = 0.001\n",
    "epochs=10\n",
    "batch_size=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_entrada = 784 # dados de entrada mnist(28x28)\n",
    "n_camada_1 = 30 #neurônios da primieira camada\n",
    "n_camada_2 = 30 # camada oculta\n",
    "n_classes = 10 # camada de saída"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variáveis preditoras e target (em forma de placeholders)\n",
    "x = tf.placeholder(tf.float32, [None, n_entrada])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pesos da camada 1\n",
    "w1= tf.Variable(tf.random_normal([n_entrada, n_camada_1], stddev=0.05))\n",
    "# Bias da camada 1\n",
    "b1 = tf.Variable(tf.zeros([n_camada_1]))\n",
    "# Camada 1\n",
    "layer_1 = tf.nn.relu(tf.add(tf.matmul(x, w1), b1))\n",
    "\n",
    "# Pesos da camada 2\n",
    "w2 = tf.Variable(tf.random_normal([n_camada_1, n_camada_2], stddev=0.05))\n",
    "# Bias da camada 2\n",
    "b2 = tf.Variable(tf.zeros([n_camada_2]))\n",
    "# Camada 2\n",
    "layer_2 = tf.nn.relu(tf.add(tf.matmul(layer_1, w2), b2)) # multiplicando os pesos pelo resultado da camada1, soma bias, aplicando relu\n",
    "\n",
    "# pesos da camada de Saida (output)\n",
    "w_out = tf.Variable(tf.random_normal([n_camada_2, n_classes], stddev=0.05))\n",
    "# Bias da camada de saída (output)\n",
    "bias_out = tf.Variable(tf.zeros([n_classes]))\n",
    "# Camada de saída (output)\n",
    "saida = tf.matmul(layer_2, w_out) + bias_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_90383/2741000827.py:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_90383/2741000827.py:5: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Função de custo\n",
    "custo = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=saida, labels=y))\n",
    "\n",
    "# Otimizador\n",
    "otimizador = tf.train.AdamOptimizer(learning_rate=lerning_rate).minimize(custo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testando o modelo\n",
    "predicoes = tf.equal(tf.argmax(saida, 1), tf.argmax(y, 1))\n",
    "# Calculando a acurácia\n",
    "acuracia = tf.reduce_mean(tf.cast(predicoes, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Custo treino 0.8407602912729433\n",
      "Acurácia teste 0.8985999822616577\n",
      "Epoch 2, Custo treino 0.32192682640119\n",
      "Acurácia teste 0.9186000227928162\n",
      "Epoch 3, Custo treino 0.26865415215492244\n",
      "Acurácia teste 0.9300000071525574\n",
      "Epoch 4, Custo treino 0.23656470916487934\n",
      "Acurácia teste 0.9366000294685364\n",
      "Epoch 5, Custo treino 0.21135544955730454\n",
      "Acurácia teste 0.9430999755859375\n",
      "Epoch 6, Custo treino 0.19169110390272998\n",
      "Acurácia teste 0.9460999965667725\n",
      "Epoch 7, Custo treino 0.1758079421249302\n",
      "Acurácia teste 0.949400007724762\n",
      "Epoch 8, Custo treino 0.1614583545381372\n",
      "Acurácia teste 0.9526000022888184\n",
      "Epoch 9, Custo treino 0.14982258425517517\n",
      "Acurácia teste 0.9538000226020813\n",
      "Epoch 10, Custo treino 0.13843095499006194\n",
      "Acurácia teste 0.9556999802589417\n",
      "Treinamento concluído!\n",
      "Acurácia do Modelo 0.9557\n"
     ]
    }
   ],
   "source": [
    "# Inicializando as variáveis\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Abrindo sessão\n",
    "with tf.Session() as sess:\n",
    "  sess.run(init)\n",
    "  # Ciclo de treinamento\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "    custo_medio = 0.0\n",
    "    total_batches = int(mnist.train.num_examples / batch_size)\n",
    "    \n",
    "    # loops por todas as iterações (batches)\n",
    "    for i in range(total_batches):\n",
    "      batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "\n",
    "      # fit training usando batch data\n",
    "      sess.run(otimizador, feed_dict={x: batch_x, y: batch_y})\n",
    "\n",
    "      # computando o custo (loss) médio de um epoch completo \n",
    "      custo_medio +=sess.run(custo, feed_dict={x: batch_x, y: batch_y}) / total_batches\n",
    "    # Rodando acurácia\n",
    "    acuracia_teste = sess.run(acuracia, feed_dict={x: mnist.test.images, y:mnist.test.labels})\n",
    "\n",
    "    # Mostrando os resultados após cada epoch\n",
    "    print(f'Epoch {epoch+1}, Custo treino {custo_medio}')\n",
    "    print(f'Acurácia teste {acuracia_teste}')\n",
    "  print('Treinamento concluído!')\n",
    "  print(f'Acurácia do Modelo', acuracia.eval({x: mnist.test.images, y:mnist.test.labels}))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.3\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
